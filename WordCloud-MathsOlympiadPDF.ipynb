{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.pdfparser import PDFParser #PDFParser fetches data from a file\n",
    "from pdfminer.pdfdocument import PDFDocument #PDFDocument stores it\n",
    "from pdfminer.pdfinterp import PDFPageInterpreter, PDFResourceManager\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "#PDFPageInterpreter to process the page contents\n",
    "# PDFResourceManager is used to store shared resources such as fonts or images\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "import io\n",
    "#PDFDevice to translate it\n",
    "\n",
    "def pdfToTextConverter(data):\n",
    "    fp = open(data, 'rb')\n",
    "    pdfResrcMgr = PDFResourceManager()\n",
    "    retstr = io.StringIO()\n",
    "    laparams = LAParams()\n",
    "    \n",
    "    device = TextConverter(pdfResrcMgr, retstr, laparams=laparams)\n",
    "    \n",
    "    # Create a PDF interpreter object.\n",
    "    interpreter = PDFPageInterpreter(pdfResrcMgr, device)\n",
    "    \n",
    "    # Process each page contained in the document.\n",
    "    for page in PDFPage.get_pages(fp):\n",
    "        interpreter.process_page(page)\n",
    "        data =  retstr.getvalue()\n",
    "\n",
    "    return data\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    file = pdfToTextConverter('MathsOlympiad.pdf')\n",
    "    \n",
    "    with open('MathsOlympiad.txt',\"wb\") as txtFile:\n",
    "        txtFile.write(file.encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"MathsOlympiad.txt\",'r')\n",
    "txt = f.read()\n",
    "f.close()\n",
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardization (Words all in lower case)\n",
    "stdTxt = txt.lower()\n",
    "stdTxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning - Remove all '\\n'\n",
    "cleanTxt1 = stdTxt.replace(\"\\n\",\" \")\n",
    "cleanTxt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning - Remove all '//'\n",
    "cleanTxt2 = cleanTxt1.replace(\"//\",\" \")\n",
    "cleanTxt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning - Remove all '/'\n",
    "cleanTxt3 = cleanTxt2.replace(\"/\",\" \")\n",
    "cleanTxt3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning - removing all special characters now\n",
    "import re\n",
    "pattern = re.compile(r\"[^a-z ]\")\n",
    "cleanTxt4 = pattern.sub(\"\",cleanTxt3)\n",
    "cleanTxt4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning - Removing all extra spaces\n",
    "cleanTxt5 = \" \".join(cleanTxt4.split())\n",
    "cleanTxt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now after cleaning, Let's Tonenize all words into a list\n",
    "from nltk.tokenize import word_tokenize\n",
    "txt_token = word_tokenize(text = cleanTxt5)\n",
    "txt_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting english Stopwords\n",
    "from nltk.corpus import stopwords \n",
    "sw = stopwords.words('english')\n",
    "sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning - Remove StopWords from the token\n",
    "cleanTxt6 = []\n",
    "for i in txt_token:\n",
    "    if i not in sw:\n",
    "        cleanTxt6.append(i)\n",
    "        \n",
    "cleanTxt6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting cleaned Token words into pandas series\n",
    "import pandas as pd\n",
    "cleanSeries = pd.Series(cleanTxt6)\n",
    "cleanSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unique words\n",
    "unik = cleanSeries.loc[-cleanSeries.duplicated()]\n",
    "unik # Unique - unik is BOW here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count of words\n",
    "cnt = cleanSeries.value_counts().sort_values(ascending=False)\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt.plot(kind=\"bar\",figsize=(10,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from wordcloud import *\n",
    "\n",
    "user_mask = np.array(Image.open('lefant.jpg'))\n",
    "user_mask\n",
    "cleanTxt7 = \"\\n\".join(cleanTxt6)\n",
    "cleanTxt7\n",
    "wordcloud = WordCloud(background_color='white',mask=user_mask).generate(cleanTxt7) \n",
    "# clean3 is the final input text - completely clean\n",
    "\n",
    "fig = plt.figure(1, figsize=(12, 12))\n",
    "plt.axis('off')\n",
    "plt.imshow(wordcloud)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
